import tensorflow as tf
from keras.layers import Layer, Dense

from tf_utilities.functions import clip_grad_by_norm, zero_nan_grad, flat_to_stddev, \
    sample_multivariate_normal


class NormalParameters(Layer):
    """Generate a pair of tensors, (mean, stddev), where stddev is either a positive vector of the
    same shape as the mean (for the univariate case) or the cholesky decomposition of the covariance
    matrix (for the multivariate case). For the univariate case, the resulting tensors are suitable
    for use as the loc and scale parameters to a tfp.distributions.Normal instance. For the
    multivariate case, the resulting tensors are suitable for use as the loc and scale_tril
    parameters to a tfp.distributions.MultivariateNormalTriL instance."""

    def __init__(self, channels: int, multivariate: bool = True, **kwargs):
        super().__init__(**kwargs)
        self.channels = int(channels)
        self.multivariate = bool(multivariate)
        self.mean = None
        self.stddev = None

    def get_config(self):
        config = super().get_config()
        config['channels'] = self.channels
        config['multivariate'] = self.multivariate
        return config

    def build(self, input_shape):
        input_shape = list(input_shape)
        assert len(input_shape) >= 2
        if self.multivariate:
            stddev_channels = self.channels * (self.channels + 1) // 2
        else:
            stddev_channels = self.channels
        self.mean = Dense(self.channels, name=self.name + '/mean')
        self.stddev = Dense(stddev_channels, name=self.name + '/stddev_flat')
        super().build(input_shape)

    def compute_output_shape(self, input_shape):
        input_shape = list(input_shape)
        assert len(input_shape) >= 2
        batch_shape = input_shape[:-1]
        mean_shape = batch_shape + [self.channels]
        if self.multivariate:
            stddev_shape = batch_shape + [self.channels, self.channels]
        else:
            stddev_shape = batch_shape + [self.channels]
        return mean_shape, stddev_shape

    # noinspection PyMethodOverriding
    def call(self, inputs):
        tf.debugging.assert_all_finite(inputs, "GaussianParameters inputs")
        mean = zero_nan_grad(clip_grad_by_norm(self.mean(inputs), 1.0))
        stddev = flat_to_stddev(zero_nan_grad(clip_grad_by_norm(self.stddev(inputs), 1.0)))
        return mean, stddev


class NormalSample(Layer):
    """Map the parameters of a normal distribution to samples from the distribution. Unlike
    those produced by tfp.distributions.MultivariateNormalTriL, samples generated by this layer have
    the appropriate gradients to learn not only the correct mean, but the correct variance --
    assuming that the loss is measured as the MSE between the sample generated by this layer and a
    sample from the target distribution."""

    def __init__(self, channels: int = None, multivariate: bool = None, **kwargs):
        super().__init__(**kwargs)
        self.channels = None if channels is None else int(channels)
        self.multivariate = None if multivariate is None else bool(multivariate)

        assert self.channels is None or self.channels > 0

    def get_config(self):
        config = super().get_config()
        config['channels'] = self.channels
        config['multivariate'] = self.multivariate
        return config

    def build(self, input_shape):
        mean_shape, stddev_shape = input_shape
        mean_shape = list(mean_shape)
        stddev_shape = list(stddev_shape)
        batch_shape = mean_shape[:-1]
        mean_channels = mean_shape[-1]
        self.channels = self.channels or mean_channels
        assert mean_channels == self.channels
        assert stddev_shape[:len(batch_shape)] == batch_shape
        if len(stddev_shape) == len(batch_shape) + 2:
            assert self.multivariate or self.multivariate is None
            assert stddev_shape[-2:] == [self.channels, self.channels]
            self.multivariate = True
        else:
            assert len(stddev_shape) == len(mean_shape)
            assert stddev_shape[-1] == self.channels
            assert not self.multivariate
            self.multivariate = False
        super().build(input_shape)

    def compute_output_shape(self, input_shape):
        mean_shape, stddev_shape = input_shape
        return mean_shape

    # noinspection PyMethodOverriding
    def call(self, inputs):
        mean, stddev = inputs

        # Handle occasional unreasonable/undefined gradients on the parameters
        mean = zero_nan_grad(clip_grad_by_norm(mean, 100.0))
        stddev = zero_nan_grad(clip_grad_by_norm(stddev, 100.0))

        if not self.multivariate:
            mean = mean[..., tf.newaxis, tf.newaxis]
            stddev = stddev[..., tf.newaxis, tf.newaxis]

        sample = sample_multivariate_normal(mean, stddev)

        if not self.multivariate:
            sample = tf.squeeze(sample, axis=-1)

        tf.assert_equal(tf.shape(mean), tf.shape(sample))
        return sample
